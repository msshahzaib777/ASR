{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "e7cf2894",
   "metadata": {},
   "outputs": [],
   "source": [
    "from os import environ, path, walk\n",
    "from pocketsphinx import *\n",
    "import fnmatch\n",
    "relative_path = \"../ps_data\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "fa35485a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_folder(path):\n",
    "    \"\"\"Create a folder if it doesn't already exist\"\"\"\n",
    "    if not os.path.isdir(path):\n",
    "        os.makedirs(path)\n",
    "    return\n",
    "\n",
    "\n",
    "def find_files(directory, pattern='*.raw'):\n",
    "    \"\"\"Recursively finds all files matching the pattern.\"\"\"\n",
    "    files = []\n",
    "    for root, dirnames, filenames in walk(directory):\n",
    "        for filename in fnmatch.filter(filenames, pattern):\n",
    "            files.append(path.join(root, filename))\n",
    "\n",
    "    # sort the list, to avoid mismatch in the output files\n",
    "    files = sorted(files)\n",
    "\n",
    "    return files\n",
    "\n",
    "\n",
    "def create_decoder_ngram():\n",
    "    \"\"\"Create a decoder based on the Ngram language model\"\"\"\n",
    "    config = Decoder.default_config()\n",
    "    config.set_string('-hmm',  relative_path +'/model/en-us')  # acoustic model\n",
    "#     config.set_string('-dict', relative_path +'/lex/turtle.dict')  # lexicon / dictionary\n",
    "#     config.set_string('-lm', relative_path +'/lm/turtle.lm.bin')  # language model\n",
    "    config.set_string('-dict', relative_path +'/lex/cmudict-en-us.dict')  # lexicon / dictionary\n",
    "    config.set_string('-lm', relative_path +'/lm/en-us.lm.bin')  # language model\n",
    "    decoder_ngram = Decoder(config)\n",
    "    return decoder_ngram\n",
    "\n",
    "\n",
    "def create_decoder_goforward():\n",
    "    \"\"\"Create a decoder based on the goforward custom grammar\"\"\"\n",
    "    config = Decoder.default_config()\n",
    "    config.set_string('-hmm', relative_path +'/model/en-us')  # acoustic model\n",
    "    config.set_string('-dict', relative_path +'/lex/turtle.dict')  # lexicon / dictionary\n",
    "    decoder_gofwd = Decoder(config)\n",
    "\n",
    "    # Now we use a custom language model\n",
    "    # Prepare the grammar to be used\n",
    "    jsgf = Jsgf(relative_path +'/jsgf/goforward.jsgf')  # load the grammar file\n",
    "    rule = jsgf.get_rule('goforward.move2')  # choose the rule\n",
    "    fsg = jsgf.build_fsg(rule, decoder_gofwd.get_logmath(), 7.5)  # build the grammar rule\n",
    "    fsg.writefile('../outputs/goforward.fsg')  # write the compiled grammar rule as an external file\n",
    "\n",
    "    # Now set the fsg grammar rule in the decoder\n",
    "    decoder_gofwd.set_fsg(\"../outputs/goforward\", fsg)  # load the pre-recorded compiled grammar rule in the decoder\n",
    "    decoder_gofwd.set_search(\"../outputs/goforward\")  # and set it as the grammar to use\n",
    "\n",
    "    return decoder_gofwd\n",
    "\n",
    "# EOF\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "8ae8b8d3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best hypothesis:  go forward ten meters \n",
      " model score:  0.7239855458606713 \n",
      " confidence:  1.0\n",
      "Best hypothesis segments:  ['<sil>', 'go', 'forward', 'ten', 'meters', '<sil>', '</s>']\n",
      "Best 8 hypothesis: \n",
      "go forward ten meters 0.7239855458606713\n",
      "go forward ten meters 0.7239855458606713\n",
      "go forward ten meters 0.7239855458606713\n",
      "go forward ten meters 0.6579153085207451\n",
      "go forward ten meters 0.6579153085207451\n",
      "go forward ten meters 0.6579153085207451\n",
      "go forward ten meters 0.6579153085207451\n",
      "go forward ten meters 0.6579153085207451\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_21310/2192241237.py:35: DeprecationWarning: default_config() is deprecated, just call Config() constructor\n",
      "  config = Decoder.default_config()\n",
      "ERROR: \"dict.c\", line 191: Line 68: Phone 'OH' is missing in the acoustic model; word 'oh(3)' ignored\n",
      "/tmp/ipykernel_21310/2192241237.py:48: DeprecationWarning: set_fsg() is deprecated, use add_fsg() instead\n",
      "  decoder_gofwd.set_fsg(\"../outputs/goforward\", fsg)  # load the pre-recorded compiled grammar rule in the decoder\n",
      "/tmp/ipykernel_21310/2192241237.py:49: DeprecationWarning: set_search() is deprecated, use activate_search() instead\n",
      "  decoder_gofwd.set_search(\"../outputs/goforward\")  # and set it as the grammar to use\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# Define the path of the file to process\n",
    "file_path = relative_path +'/example/goforward.raw'\n",
    "\n",
    "# Instantiate the decoder\n",
    "# decoder = create_decoder_ngram()  # use the N-gram language model\n",
    "decoder = create_decoder_goforward()  # use the custom grammar\n",
    "\n",
    "# Start the decoder\n",
    "decoder.start_utt()\n",
    "\n",
    "# Open the file to decode\n",
    "stream = open(file_path, 'rb')\n",
    "uttbuf = stream.read(-1)\n",
    "\n",
    "# Process the file with the decoder\n",
    "if uttbuf:\n",
    "    decoder.process_raw(uttbuf, False, True)\n",
    "else:\n",
    "    print(\"Error reading speech data\")\n",
    "    exit()\n",
    "decoder.end_utt()\n",
    "\n",
    "# test for empty hypothesis and replace the output with an empty string if needed\n",
    "if decoder.hyp() is None:\n",
    "    best_hypothesis = ''\n",
    "else:\n",
    "    best_hypothesis = decoder.hyp().hypstr\n",
    "\n",
    "# Print the results\n",
    "print('Best hypothesis: ', best_hypothesis,\n",
    "      \"\\n model score: \", decoder.hyp().best_score,\n",
    "      \"\\n confidence: \", decoder.get_logmath().exp(decoder.hyp().prob))\n",
    "\n",
    "print('Best hypothesis segments: ', [seg.word for seg in decoder.seg()])\n",
    "\n",
    "# Access N best decodings\n",
    "N = 8\n",
    "print('Best ' + str(N) + ' hypothesis: ')\n",
    "for best, i in zip(decoder.nbest(), range(N)):\n",
    "    print(best.hypstr, best.score)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "f5759659",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_21310/2192241237.py:23: DeprecationWarning: default_config() is deprecated, just call Config() constructor\n",
      "  config = Decoder.default_config()\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best hypothesis:  one eight \n",
      " model score:  0.6008112061264117 \n",
      " confidence:  1.0\n",
      "Best hypothesis segments:  ['<s>', 'one(2)', 'eight', '</s>']\n",
      "Best 8 hypothesis: \n",
      "one eight 0.076361900742479\n",
      "one egg 0.07543599137899455\n",
      "one mate 0.07520251355700776\n",
      "one made 0.07487985309859328\n",
      "one a 0.0747451973222464\n",
      "one make 0.07436498618859971\n",
      "one aide 0.07409035784661228\n",
      "what made 0.07406813518393898\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# Define the path of the file to process\n",
    "file_path = relative_path +'/example/ex_digits.raw'\n",
    "\n",
    "# Instantiate the decoder\n",
    "decoder = create_decoder_ngram()  # use the N-gram language model\n",
    "# decoder = create_decoder_goforward()  # use the custom grammar\n",
    "\n",
    "# Start the decoder\n",
    "decoder.start_utt()\n",
    "\n",
    "# Open the file to decode\n",
    "stream = open(file_path, 'rb')\n",
    "uttbuf = stream.read(-1)\n",
    "\n",
    "# Process the file with the decoder\n",
    "if uttbuf:\n",
    "    decoder.process_raw(uttbuf, False, True)\n",
    "else:\n",
    "    print(\"Error reading speech data\")\n",
    "    exit()\n",
    "decoder.end_utt()\n",
    "\n",
    "# test for empty hypothesis and replace the output with an empty string if needed\n",
    "if decoder.hyp() is None:\n",
    "    best_hypothesis = ''\n",
    "else:\n",
    "    best_hypothesis = decoder.hyp().hypstr\n",
    "\n",
    "# Print the results\n",
    "print('Best hypothesis: ', best_hypothesis,\n",
    "      \"\\n model score: \", decoder.hyp().best_score,\n",
    "      \"\\n confidence: \", decoder.get_logmath().exp(decoder.hyp().prob))\n",
    "\n",
    "print('Best hypothesis segments: ', [seg.word for seg in decoder.seg()])\n",
    "\n",
    "# Access N best decodings\n",
    "N = 8\n",
    "print('Best ' + str(N) + ' hypothesis: ')\n",
    "for best, i in zip(decoder.nbest(), range(N)):\n",
    "    print(best.hypstr, best.score)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cee23d69",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
