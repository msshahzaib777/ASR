{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "e7cf2894",
   "metadata": {},
   "outputs": [],
   "source": [
    "from os import environ, path, walk\n",
    "from pocketsphinx import *\n",
    "from sphinxbase import *\n",
    "import fnmatch\n",
    "relative_path = \"../ps_data\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "fa35485a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_folder(path):\n",
    "    \"\"\"Create a folder if it doesn't already exist\"\"\"\n",
    "    if not os.path.isdir(path):\n",
    "        os.makedirs(path)\n",
    "    return\n",
    "\n",
    "\n",
    "def find_files(directory, pattern='*.raw'):\n",
    "    \"\"\"Recursively finds all files matching the pattern.\"\"\"\n",
    "    files = []\n",
    "    for root, dirnames, filenames in walk(directory):\n",
    "        for filename in fnmatch.filter(filenames, pattern):\n",
    "            files.append(path.join(root, filename))\n",
    "\n",
    "    # sort the list, to avoid mismatch in the output files\n",
    "    files = sorted(files)\n",
    "\n",
    "    return files\n",
    "\n",
    "\n",
    "def create_decoder_ngram():\n",
    "    \"\"\"Create a decoder based on the Ngram language model\"\"\"\n",
    "    config = Decoder.default_config()\n",
    "    config.set_string('-hmm',  relative_path +'/model/en-us')  # acoustic model\n",
    "#     config.set_string('-dict', relative_path +'/lex/turtle.dict')  # lexicon / dictionary\n",
    "#     config.set_string('-lm', relative_path +'/lm/turtle.lm.bin')  # language model\n",
    "    config.set_string('-dict', relative_path +'/lex/cmudict-en-us.dict')  # lexicon / dictionary\n",
    "    config.set_string('-lm', relative_path +'/lm/en-us.lm.bin')  # language model\n",
    "    decoder_ngram = Decoder(config)\n",
    "    return decoder_ngram\n",
    "\n",
    "\n",
    "def create_decoder_goforward():\n",
    "    \"\"\"Create a decoder based on the goforward custom grammar\"\"\"\n",
    "    config = Decoder.default_config()\n",
    "    config.set_string('-hmm', relative_path +'/model/en-us')  # acoustic model\n",
    "    config.set_string('-dict', relative_path +'/lex/turtle.dict')  # lexicon / dictionary\n",
    "    decoder_gofwd = Decoder(config)\n",
    "\n",
    "    # Now we use a custom language model\n",
    "    # Prepare the grammar to be used\n",
    "    jsgf = Jsgf(relative_path +'/jsgf/goforward.jsgf')  # load the grammar file\n",
    "    rule = jsgf.get_rule('goforward.move2')  # choose the rule\n",
    "    fsg = jsgf.build_fsg(rule, decoder_gofwd.get_logmath(), 7.5)  # build the grammar rule\n",
    "    fsg.writefile('../outputs/goforward.fsg')  # write the compiled grammar rule as an external file\n",
    "\n",
    "    # Now set the fsg grammar rule in the decoder\n",
    "    decoder_gofwd.set_fsg(\"../outputs/goforward\", fsg)  # load the pre-recorded compiled grammar rule in the decoder\n",
    "    decoder_gofwd.set_search(\"../outputs/goforward\")  # and set it as the grammar to use\n",
    "\n",
    "    return decoder_gofwd\n",
    "\n",
    "# EOF\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "8ae8b8d3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best hypothesis:  go forward ten meters \n",
      " model score:  -3002 \n",
      " confidence:  1.0\n",
      "Best hypothesis segments:  ['<sil>', 'go', 'forward', 'ten', 'meters', '<sil>']\n",
      "Best 8 hypothesis: \n",
      "go forward ten meters -2389\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO: pocketsphinx.c(151): Parsed model-specific feature parameters from ../ps_data/model/en-us/feat.params\n",
      "Current configuration:\n",
      "[NAME]\t\t\t[DEFLT]\t\t[VALUE]\n",
      "-agc\t\t\tnone\t\tnone\n",
      "-agcthresh\t\t2.0\t\t2.000000e+00\n",
      "-allphone\t\t\t\t\n",
      "-allphone_ci\t\tyes\t\tyes\n",
      "-alpha\t\t\t0.97\t\t9.700000e-01\n",
      "-ascale\t\t\t20.0\t\t2.000000e+01\n",
      "-aw\t\t\t1\t\t1\n",
      "-backtrace\t\tno\t\tno\n",
      "-beam\t\t\t1e-48\t\t1.000000e-48\n",
      "-bestpath\t\tyes\t\tyes\n",
      "-bestpathlw\t\t9.5\t\t9.500000e+00\n",
      "-ceplen\t\t\t13\t\t13\n",
      "-cmn\t\t\tlive\t\tbatch\n",
      "-cmninit\t\t40,3,-1\t\t41.00,-5.29,-0.12,5.09,2.48,-4.07,-1.37,-1.78,-5.08,-2.05,-6.45,-1.42,1.17\n",
      "-compallsen\t\tno\t\tno\n",
      "-dict\t\t\t\t\t../ps_data/lex/turtle.dict\n",
      "-dictcase\t\tno\t\tno\n",
      "-dither\t\t\tno\t\tno\n",
      "-doublebw\t\tno\t\tno\n",
      "-ds\t\t\t1\t\t1\n",
      "-fdict\t\t\t\t\t\n",
      "-feat\t\t\t1s_c_d_dd\t1s_c_d_dd\n",
      "-featparams\t\t\t\t\n",
      "-fillprob\t\t1e-8\t\t1.000000e-08\n",
      "-frate\t\t\t100\t\t100\n",
      "-fsg\t\t\t\t\t\n",
      "-fsgusealtpron\t\tyes\t\tyes\n",
      "-fsgusefiller\t\tyes\t\tyes\n",
      "-fwdflat\t\tyes\t\tyes\n",
      "-fwdflatbeam\t\t1e-64\t\t1.000000e-64\n",
      "-fwdflatefwid\t\t4\t\t4\n",
      "-fwdflatlw\t\t8.5\t\t8.500000e+00\n",
      "-fwdflatsfwin\t\t25\t\t25\n",
      "-fwdflatwbeam\t\t7e-29\t\t7.000000e-29\n",
      "-fwdtree\t\tyes\t\tyes\n",
      "-hmm\t\t\t\t\t../ps_data/model/en-us\n",
      "-input_endian\t\tlittle\t\tlittle\n",
      "-jsgf\t\t\t\t\t\n",
      "-keyphrase\t\t\t\t\n",
      "-kws\t\t\t\t\t\n",
      "-kws_delay\t\t10\t\t10\n",
      "-kws_plp\t\t1e-1\t\t1.000000e-01\n",
      "-kws_threshold\t\t1e-30\t\t1.000000e-30\n",
      "-latsize\t\t5000\t\t5000\n",
      "-lda\t\t\t\t\t\n",
      "-ldadim\t\t\t0\t\t0\n",
      "-lifter\t\t\t0\t\t22\n",
      "-lm\t\t\t\t\t\n",
      "-lmctl\t\t\t\t\t\n",
      "-lmname\t\t\t\t\t\n",
      "-logbase\t\t1.0001\t\t1.000100e+00\n",
      "-logfn\t\t\t\t\t\n",
      "-logspec\t\tno\t\tno\n",
      "-lowerf\t\t\t133.33334\t1.300000e+02\n",
      "-lpbeam\t\t\t1e-40\t\t1.000000e-40\n",
      "-lponlybeam\t\t7e-29\t\t7.000000e-29\n",
      "-lw\t\t\t6.5\t\t6.500000e+00\n",
      "-maxhmmpf\t\t30000\t\t30000\n",
      "-maxwpf\t\t\t-1\t\t-1\n",
      "-mdef\t\t\t\t\t\n",
      "-mean\t\t\t\t\t\n",
      "-mfclogdir\t\t\t\t\n",
      "-min_endfr\t\t0\t\t0\n",
      "-mixw\t\t\t\t\t\n",
      "-mixwfloor\t\t0.0000001\t1.000000e-07\n",
      "-mllr\t\t\t\t\t\n",
      "-mmap\t\t\tyes\t\tyes\n",
      "-ncep\t\t\t13\t\t13\n",
      "-nfft\t\t\t512\t\t512\n",
      "-nfilt\t\t\t40\t\t25\n",
      "-nwpen\t\t\t1.0\t\t1.000000e+00\n",
      "-pbeam\t\t\t1e-48\t\t1.000000e-48\n",
      "-pip\t\t\t1.0\t\t1.000000e+00\n",
      "-pl_beam\t\t1e-10\t\t1.000000e-10\n",
      "-pl_pbeam\t\t1e-10\t\t1.000000e-10\n",
      "-pl_pip\t\t\t1.0\t\t1.000000e+00\n",
      "-pl_weight\t\t3.0\t\t3.000000e+00\n",
      "-pl_window\t\t5\t\t5\n",
      "-rawlogdir\t\t\t\t\n",
      "-remove_dc\t\tno\t\tno\n",
      "-remove_noise\t\tyes\t\tyes\n",
      "-remove_silence\t\tyes\t\tyes\n",
      "-round_filters\t\tyes\t\tyes\n",
      "-samprate\t\t16000\t\t1.600000e+04\n",
      "-seed\t\t\t-1\t\t-1\n",
      "-sendump\t\t\t\t\n",
      "-senlogdir\t\t\t\t\n",
      "-senmgau\t\t\t\t\n",
      "-silprob\t\t0.005\t\t5.000000e-03\n",
      "-smoothspec\t\tno\t\tno\n",
      "-svspec\t\t\t\t\t0-12/13-25/26-38\n",
      "-tmat\t\t\t\t\t\n",
      "-tmatfloor\t\t0.0001\t\t1.000000e-04\n",
      "-topn\t\t\t4\t\t4\n",
      "-topn_beam\t\t0\t\t0\n",
      "-toprule\t\t\t\t\n",
      "-transform\t\tlegacy\t\tdct\n",
      "-unit_area\t\tyes\t\tyes\n",
      "-upperf\t\t\t6855.4976\t6.800000e+03\n",
      "-uw\t\t\t1.0\t\t1.000000e+00\n",
      "-vad_postspeech\t\t50\t\t50\n",
      "-vad_prespeech\t\t20\t\t20\n",
      "-vad_startspeech\t10\t\t10\n",
      "-vad_threshold\t\t3.0\t\t3.000000e+00\n",
      "-var\t\t\t\t\t\n",
      "-varfloor\t\t0.0001\t\t1.000000e-04\n",
      "-varnorm\t\tno\t\tno\n",
      "-verbose\t\tno\t\tno\n",
      "-warp_params\t\t\t\t\n",
      "-warp_type\t\tinverse_linear\tinverse_linear\n",
      "-wbeam\t\t\t7e-29\t\t7.000000e-29\n",
      "-wip\t\t\t0.65\t\t6.500000e-01\n",
      "-wlen\t\t\t0.025625\t2.562500e-02\n",
      "\n",
      "INFO: feat.c(713): Initializing feature stream to type: '1s_c_d_dd', ceplen=13, CMN='batch', VARNORM='no', AGC='none'\n",
      "INFO: acmod.c(161): Using subvector specification 0-12/13-25/26-38\n",
      "INFO: mdef.c(518): Reading model definition: ../ps_data/model/en-us/mdef\n",
      "INFO: mdef.c(529): Found byte-order mark BMDF, assuming this is a binary mdef file\n",
      "INFO: bin_mdef.c(336): Reading binary model definition: ../ps_data/model/en-us/mdef\n",
      "INFO: bin_mdef.c(513): 42 CI-phone, 137053 CD-phone, 3 emitstate/phone, 126 CI-sen, 5126 Sen, 29324 Sen-Seq\n",
      "INFO: tmat.c(148): Reading HMM transition probability matrices: ../ps_data/model/en-us/transition_matrices\n",
      "INFO: acmod.c(113): Attempting to use PTM computation module\n",
      "INFO: ms_gauden.c(127): Reading mixture gaussian parameter: ../ps_data/model/en-us/means\n",
      "INFO: ms_gauden.c(242): 42 codebook, 3 feature, size: \n",
      "INFO: ms_gauden.c(244):  128x13\n",
      "INFO: ms_gauden.c(244):  128x13\n",
      "INFO: ms_gauden.c(244):  128x13\n",
      "INFO: ms_gauden.c(127): Reading mixture gaussian parameter: ../ps_data/model/en-us/variances\n",
      "INFO: ms_gauden.c(242): 42 codebook, 3 feature, size: \n",
      "INFO: ms_gauden.c(244):  128x13\n",
      "INFO: ms_gauden.c(244):  128x13\n",
      "INFO: ms_gauden.c(244):  128x13\n",
      "INFO: ms_gauden.c(304): 222 variance values floored\n",
      "INFO: ptm_mgau.c(475): Loading senones from dump file ../ps_data/model/en-us/sendump\n",
      "INFO: ptm_mgau.c(499): BEGIN FILE FORMAT DESCRIPTION\n",
      "INFO: ptm_mgau.c(562): Rows: 128, Columns: 5126\n",
      "INFO: ptm_mgau.c(594): Using memory-mapped I/O for senones\n",
      "INFO: ptm_mgau.c(837): Maximum top-N: 4\n",
      "INFO: phone_loop_search.c(113): State beam -225 Phone exit beam -225 Insertion penalty 0\n",
      "INFO: dict.c(318): Allocating 4211 * 32 bytes (131 KiB) for word entries\n",
      "INFO: dict.c(333): Reading main dictionary: ../ps_data/lex/turtle.dict\n",
      "INFO: dict.c(212): Dictionary size 110, allocated 0 KiB for strings, 0 KiB for phones\n",
      "INFO: dict.c(336): 110 words read\n",
      "INFO: dict.c(358): Reading filler dictionary: ../ps_data/model/en-us/noisedict\n",
      "INFO: dict.c(212): Dictionary size 115, allocated 0 KiB for strings, 0 KiB for phones\n",
      "INFO: dict.c(361): 5 words read\n",
      "INFO: dict2pid.c(396): Building PID tables for dictionary\n",
      "INFO: dict2pid.c(404): Allocating 42^3 * 2 bytes (144 KiB) for word-initial triphones\n",
      "INFO: dict2pid.c(131): Allocated 42672 bytes (41 KiB) for word-final triphones\n",
      "INFO: dict2pid.c(195): Allocated 42672 bytes (41 KiB) for single-phone word triphones\n",
      "INFO: jsgf.c(708): Defined rule: PUBLIC <goforward.move>\n",
      "INFO: jsgf.c(708): Defined rule: <goforward.g00001>\n",
      "INFO: jsgf.c(708): Defined rule: PUBLIC <goforward.move2>\n",
      "INFO: jsgf.c(708): Defined rule: <goforward.direction>\n",
      "INFO: jsgf.c(708): Defined rule: <goforward.distance>\n",
      "INFO: fsg_model.c(208): Computing transitive closure for null transitions\n",
      "INFO: fsg_model.c(270): 0 null transitions added\n",
      "INFO: fsg_model.c(843): Writing FSG file '../outputs/goforward.fsg'\n",
      "INFO: fsg_search.c(225): FSG(beam: -1080, pbeam: -1080, wbeam: -634; wip: -26, pip: 0)\n",
      "INFO: fsg_model.c(423): Adding silence transitions for <sil> to FSG\n",
      "INFO: fsg_model.c(443): Added 5 silence word transitions\n",
      "INFO: fsg_model.c(423): Adding silence transitions for <sil> to FSG\n",
      "INFO: fsg_model.c(443): Added 5 silence word transitions\n",
      "INFO: fsg_model.c(423): Adding silence transitions for [NOISE] to FSG\n",
      "INFO: fsg_model.c(443): Added 5 silence word transitions\n",
      "INFO: fsg_search.c(173): Added 1 alternate word transitions\n",
      "INFO: fsg_lextree.c(108): Allocated 430 bytes (0 KiB) for left and right context phones\n",
      "INFO: fsg_lextree.c(255): 92 HMM nodes in lextree (53 leaves)\n",
      "INFO: fsg_lextree.c(257): Allocated 13248 bytes (12 KiB) for all lextree nodes\n",
      "INFO: fsg_lextree.c(260): Allocated 7632 bytes (7 KiB) for lextree leafnodes\n",
      "INFO: ngram_search_fwdtree.c(427): TOTAL fwdtree 0.46 CPU 0.293 xRT\n",
      "INFO: ngram_search_fwdtree.c(430): TOTAL fwdtree 0.46 wall 0.293 xRT\n",
      "INFO: ngram_search_fwdflat.c(174): TOTAL fwdflat 0.07 CPU 0.045 xRT\n",
      "INFO: ngram_search_fwdflat.c(177): TOTAL fwdflat 0.07 wall 0.045 xRT\n",
      "INFO: ngram_search.c(301): TOTAL bestpath 0.00 CPU 0.002 xRT\n",
      "INFO: ngram_search.c(304): TOTAL bestpath 0.00 wall 0.002 xRT\n",
      "INFO: cmn.c(133): CMN: 41.00 -5.29 -0.12  5.09  2.48 -4.07 -1.37 -1.78 -5.08 -2.05 -6.45 -1.42  1.17 \n",
      "INFO: fsg_search.c(853): 264 frames, 2589 HMMs (9/fr), 9477 senones (35/fr), 614 history entries (2/fr)\n",
      "\n",
      "INFO: fsg_search.c(868): fsg 0.03 CPU 0.010 xRT\n",
      "INFO: fsg_search.c(870): fsg 0.03 wall 0.010 xRT\n",
      "INFO: fsg_search.c(1250): Start node <sil>.0:2:52\n",
      "INFO: fsg_search.c(1289): End node <sil>.212:214:263 (-555)\n",
      "INFO: fsg_search.c(1513): lattice start node <sil>.0 end node <sil>.212\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# Define the path of the file to process\n",
    "file_path = relative_path +'/example/goforward.raw'\n",
    "\n",
    "# Instantiate the decoder\n",
    "# decoder = create_decoder_ngram()  # use the N-gram language model\n",
    "decoder = create_decoder_goforward()  # use the custom grammar\n",
    "\n",
    "# Start the decoder\n",
    "decoder.start_utt()\n",
    "\n",
    "# Open the file to decode\n",
    "stream = open(file_path, 'rb')\n",
    "uttbuf = stream.read(-1)\n",
    "\n",
    "# Process the file with the decoder\n",
    "if uttbuf:\n",
    "    decoder.process_raw(uttbuf, False, True)\n",
    "else:\n",
    "    print(\"Error reading speech data\")\n",
    "    exit()\n",
    "decoder.end_utt()\n",
    "\n",
    "# test for empty hypothesis and replace the output with an empty string if needed\n",
    "if decoder.hyp() is None:\n",
    "    best_hypothesis = ''\n",
    "else:\n",
    "    best_hypothesis = decoder.hyp().hypstr\n",
    "\n",
    "# Print the results\n",
    "print('Best hypothesis: ', best_hypothesis,\n",
    "      \"\\n model score: \", decoder.hyp().best_score,\n",
    "      \"\\n confidence: \", decoder.get_logmath().exp(decoder.hyp().prob))\n",
    "\n",
    "print('Best hypothesis segments: ', [seg.word for seg in decoder.seg()])\n",
    "\n",
    "# Access N best decodings\n",
    "N = 8\n",
    "print('Best ' + str(N) + ' hypothesis: ')\n",
    "for best, i in zip(decoder.nbest(), range(N)):\n",
    "    print(best.hypstr, best.score)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0412a9db-de17-498d-82f3-8f7871cbbd38",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "62c5ad4e87eec4c5a17c3572f52b7ecf3c74993b0a3e5f72d27ab19a1fb42cb4"
  },
  "kernelspec": {
   "display_name": "Python 3.8.10 ('venv': venv)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
